<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>My Solo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://selfsolo.com/"/>
  <updated>2019-09-16T11:49:57.176Z</updated>
  <id>https://selfsolo.com/</id>
  
  <author>
    <name>Sera Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>黑盒扫描</title>
    <link href="https://selfsolo.com/2019/09/15/%E9%BB%91%E7%9B%92%E6%89%AB%E6%8F%8F/"/>
    <id>https://selfsolo.com/2019/09/15/黑盒扫描/</id>
    <published>2019-09-15T03:02:51.000Z</published>
    <updated>2019-09-16T11:49:57.176Z</updated>
    
    <content type="html"><![CDATA[<p>黑盒扫描应该是很基本的一个安全产品，可以用很低的成本去发现安全问题，同时提升SDL渗透的效率。</p><a id="more"></a><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>黑盒扫描的目的主要有两个：</p><ol><li>资产发现</li><li>漏洞扫描</li></ol><p>扫描器的效率和表现方面，单机可以用多进程+协程的方式去提qps，资源够也可以使用分布式，如：kafka / celery（后者感觉更重一点，虽然能帮你做很多事情）</p><p>我踩坑设计了一个主要依靠redis做任务的分发和pull执行（主要想糙快猛地实现），现在看来效率的确是因为架构设计有问题导致整体表现不尽如人意。</p><p>自己后来想的一个理想的架构设计：</p><p><img src="https://ser4wang.oss-cn-beijing.aliyuncs.com/Lark20190916-184509.png" alt></p><h2 id="子域名搜集"><a href="#子域名搜集" class="headerlink" title="子域名搜集"></a>子域名搜集</h2><p>子域名搜集是信息搜集里很关键的一步，因为它拓展了很大一部分的攻击面。下面是我对子域名搜集的实践。</p><p>我用python实现了一个子域名搜集工具，主要用到的方法有：</p><ol><li>基于字典</li><li>开源情报 和 搜索引擎</li><li>IP反查</li><li>TLS证书获取</li></ol><p>我使用的前者，部署最方便。</p><p>整体架构：</p><p><img src="https://ser4wang.oss-cn-beijing.aliyuncs.com/Lark20190916-184731.png" alt></p><p>这是单机跑的非理想情况，4核8g，60%cpu，800-1500qps</p><p>几个大小问题：</p><ol><li>域名泛解析</li><li>域名去重</li><li>比较依赖redis</li></ol><p>泛解析有两种解决方式，一种是ip-domain的hash map超过了阈值，最后做清洗；另一种是查完了，就做一次 &lt;随机前缀.目标域名&gt;的查询，判断是否存在，这样（和清洗一个道理）。实际做下来是1方便，因为第二种方式，如果在做判断的同时，有其他做dns query的查到了结果，就会被绕过存入data。</p><p>域名去重是因为首先引入了开源情报和搜索引擎，还有后续得到的CNAME啊，NS啊之类的，不做去重，任务队列可能就大了两三倍。我去重主要依赖redis的set，这样又回引入大key问题，解决大key，可以根据域名的级数（多少个&lt;.&gt;）分去重set，也可以大key分小key，因为并发，暂时没想到好的设计，优化考虑用布隆过滤器去做去重。</p><p>依赖redis，前面有提到，后面就不赘述了。</p><h2 id="敏感文件扫描"><a href="#敏感文件扫描" class="headerlink" title="敏感文件扫描"></a>敏感文件扫描</h2><p>这个我实现的很简单，主要看了github上几个老前辈的实现，总结了一下，可以这样做：</p><ol><li>对目标做一次全站链接爬取（需要考虑url去重）</li><li>根据links生成一级级目录</li><li>配合对应字典，做验证。</li></ol><p>其实有了目录+对应漏洞的字典，主要就是验证了。这块同时可以验证的漏洞有很多，除了敏感文件泄漏，还有目录遍历，未授权访问等等。后者可以通过打分策略来做（实现比较low，也可以用图像识别，ML做）。</p><h2 id="漏洞验证"><a href="#漏洞验证" class="headerlink" title="漏洞验证"></a>漏洞验证</h2><p>可以找一个社区比较大的（poc贡献多），因为一个是自己写poc需要很多时间。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;黑盒扫描应该是很基本的一个安全产品，可以用很低的成本去发现安全问题，同时提升SDL渗透的效率。&lt;/p&gt;
    
    </summary>
    
    
      <category term="security" scheme="https://selfsolo.com/categories/security/"/>
    
    
      <category term="扫描器" scheme="https://selfsolo.com/tags/%E6%89%AB%E6%8F%8F%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>旧Blog不再使用，重新审视自己</title>
    <link href="https://selfsolo.com/2019/09/14/hello-world/"/>
    <id>https://selfsolo.com/2019/09/14/hello-world/</id>
    <published>2019-09-14T12:04:30.577Z</published>
    <updated>2019-09-15T02:24:06.913Z</updated>
    
    <content type="html"><![CDATA[<p>从大一接触安全，懵懵懂懂直到临近毕业，再到字节实习，认识了很多技术大佬，它山之高，让我看到了很多不同的层面和角度，想把这个blog作为道标，重新开始一条严谨对待自己和人生的技术之路。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从大一接触安全，懵懵懂懂直到临近毕业，再到字节实习，认识了很多技术大佬，它山之高，让我看到了很多不同的层面和角度，想把这个blog作为道标，重新开始一条严谨对待自己和人生的技术之路。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
